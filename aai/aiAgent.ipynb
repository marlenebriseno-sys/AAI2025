{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhtMvLrc0gdZDmOtUPJBHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myrah/AAI2025/blob/dev/aai/aiAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "4aeEl41rvN57",
        "outputId": "801cf3dd-6623-44b4-8b7a-dfbcd0aa820f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Chatbot initialized. Welcome to our support center!\n",
            "🤖 You can type 'quit' at any time to exit.\n",
            "\n",
            "Greeter Agent: How can I help you today?\n",
            "You: billing\n",
            "\n",
            "System: Analyzing your request and finding the right agent...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 455.56ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "System: Sorry, there was an error with our routing agent: 404 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Configuration ---\n",
        "# IMPORTANT: Replace \"YOUR_API_KEY\" with your actual Gemini API key.\n",
        "# You can also set this as an environment variable named 'GEMINI_API_KEY'\n",
        "\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# --- Agent Definitions ---\n",
        "\n",
        "class GeminiAgent:\n",
        "    \"\"\"A base class for a Gemini-powered agent.\"\"\"\n",
        "    def __init__(self, model_name=\"gemini-pro\", system_prompt=None):\n",
        "        \"\"\"\n",
        "        Initializes the agent.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): The name of the Gemini model to use.\n",
        "            system_prompt (str): A system-level instruction to guide the model's behavior.\n",
        "        \"\"\"\n",
        "        if API_KEY == 'GOOGLE_API_KEY':\n",
        "            raise ValueError(\"Please replace 'YOUR_API_KEY' with your actual Gemini API key.\")\n",
        "\n",
        "        genai.configure(api_key=API_KEY)\n",
        "\n",
        "        generation_config = {\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 1,\n",
        "            \"top_k\": 1,\n",
        "            \"max_output_tokens\": 2048,\n",
        "        }\n",
        "\n",
        "        self.model = genai.GenerativeModel(\n",
        "            model_name=model_name,\n",
        "            generation_config=generation_config,\n",
        "            system_instruction=system_prompt\n",
        "        )\n",
        "        self.conversation = self.model.start_chat(history=[])\n",
        "\n",
        "    def send_message(self, message):\n",
        "        \"\"\"Sends a message to the Gemini model and returns the response.\"\"\"\n",
        "        response = self.conversation.send_message(message)\n",
        "        return response.text\n",
        "\n",
        "# --- Specialist Agent Prompts ---\n",
        "\n",
        "TRIAGE_PROMPT = \"\"\"\n",
        "You are a Triage Agent. Your job is to analyze the user's request and route them to the correct department.\n",
        "You must respond with ONLY ONE of the following three options:\n",
        "- 'Technical Support'\n",
        "- 'Billing'\n",
        "- 'General Inquiry'\n",
        "\"\"\"\n",
        "\n",
        "TECHNICAL_SUPPORT_PROMPT = \"\"\"\n",
        "You are a friendly and helpful Technical Support Agent.\n",
        "Your goal is to patiently and clearly guide the user to solve their technical issue.\n",
        "Start by acknowledging their problem and then ask for specific details.\n",
        "\"\"\"\n",
        "\n",
        "BILLING_PROMPT = \"\"\"\n",
        "You are a professional and courteous Billing Agent.\n",
        "Your goal is to help users with their billing, payment, or subscription questions.\n",
        "Start by politely asking for an account number or invoice ID to locate their information.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# --- Main Application Logic ---\n",
        "\n",
        "def main():\n",
        "    \"\"\"The main function to run the multi-agent chatbot.\"\"\"\n",
        "\n",
        "    print(\"🤖 Chatbot initialized. Welcome to our support center!\")\n",
        "    print(\"🤖 You can type 'quit' at any time to exit.\")\n",
        "\n",
        "    # 1. GREETING\n",
        "    # The initial greeting is handled by the main script.\n",
        "    initial_prompt = \"How can I help you today?\"\n",
        "    print(f\"\\nGreeter Agent: {initial_prompt}\")\n",
        "\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        print(\"Goodbye!\")\n",
        "        return\n",
        "\n",
        "    # 2. TRIAGE\n",
        "    # The Triage Agent decides where to send the user.\n",
        "    print(\"\\nSystem: Analyzing your request and finding the right agent...\")\n",
        "    triage_agent = GeminiAgent(system_prompt=TRIAGE_PROMPT)\n",
        "\n",
        "    # We only send the user's first message to the Triage agent.\n",
        "    try:\n",
        "        route = triage_agent.send_message(user_input).strip().lower()\n",
        "    except Exception as e:\n",
        "        print(f\"\\nSystem: Sorry, there was an error with our routing agent: {e}\")\n",
        "        return\n",
        "\n",
        "    specialist_agent = None\n",
        "    agent_name = \"\"\n",
        "\n",
        "    # 3. ROUTING\n",
        "    # Based on the triage result, select the correct specialist agent.\n",
        "    if 'technical support' in route:\n",
        "        print(\"System: Routing to Technical Support...\")\n",
        "        agent_name = \"Technical Support Agent\"\n",
        "        specialist_agent = GeminiAgent(system_prompt=TECHNICAL_SUPPORT_PROMPT)\n",
        "    elif 'billing' in route:\n",
        "        print(\"System: Routing to Billing Department...\")\n",
        "        agent_name = \"Billing Agent\"\n",
        "        specialist_agent = GeminiAgent(system_prompt=BILLING_PROMPT)\n",
        "    else:\n",
        "        print(\"System: Routing to General Inquiry...\")\n",
        "        agent_name = \"General Inquiry Agent\"\n",
        "        # Using a default agent with no special prompt\n",
        "        specialist_agent = GeminiAgent(system_prompt=\"You are a helpful general inquiry agent.\")\n",
        "\n",
        "    # 4. CONVERSATION with the Specialist\n",
        "    # The specialist agent takes over the conversation.\n",
        "\n",
        "    # The specialist needs the user's first message to have context.\n",
        "    try:\n",
        "        response = specialist_agent.send_message(user_input)\n",
        "        print(f\"\\n{agent_name}: {response}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nSystem: Sorry, there was an error with our specialist agent: {e}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    # Loop for continuous conversation with the specialist\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"Thank you for chatting with us. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            response = specialist_agent.send_message(user_input)\n",
        "            print(f\"\\n{agent_name}: {response}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nSystem: An error occurred: {e}\")\n",
        "            break\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}