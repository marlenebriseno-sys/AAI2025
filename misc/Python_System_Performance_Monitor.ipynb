{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myrah/AAI2025/blob/dev/misc/Python_System_Performance_Monitor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "#\n",
        "# system_performance_monitor.py\n",
        "#\n",
        "# Description:\n",
        "# A Python script to monitor and log system performance metrics, specifically\n",
        "# CPU usage and memory usage, at regular intervals.\n",
        "#\n",
        "# Dependencies:\n",
        "# - psutil: A cross-platform library for retrieving information on running\n",
        "#           processes and system utilization (CPU, memory, disks, network, sensors).\n",
        "#\n",
        "# Installation:\n",
        "# pip install psutil\n",
        "#\n",
        "# Usage:\n",
        "# python system_performance_monitor.py\n",
        "\n",
        "import psutil\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def get_system_performance():\n",
        "    \"\"\"\n",
        "    Retrieves the current CPU and memory usage.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the CPU usage percentage and memory usage percentage.\n",
        "    \"\"\"\n",
        "    # Get CPU usage percentage. interval=1 means it's a non-blocking call\n",
        "    # that compares system CPU times elapsed since the last call.\n",
        "    cpu_usage = psutil.cpu_percent(interval=1)\n",
        "\n",
        "    # Get memory usage details\n",
        "    memory_info = psutil.virtual_memory()\n",
        "    memory_usage = memory_info.percent\n",
        "\n",
        "    return cpu_usage, memory_usage\n",
        "\n",
        "def log_performance_data(log_file=\"system_performance.log\"):\n",
        "    \"\"\"\n",
        "    Logs the system performance data to a file.\n",
        "\n",
        "    Args:\n",
        "        log_file (str): The name of the file to which the logs will be written.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(log_file, \"a\") as f:\n",
        "            # Loop indefinitely until interrupted by the user (e.g., Ctrl+C)\n",
        "            while True:\n",
        "                # Get the current timestamp\n",
        "                timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "                # Get performance data\n",
        "                cpu, memory = get_system_performance()\n",
        "\n",
        "                # Format the log entry\n",
        "                log_entry = f\"{timestamp} - CPU Usage: {cpu}%, Memory Usage: {memory}%\\n\"\n",
        "\n",
        "                # Print to console\n",
        "                print(log_entry, end=\"\")\n",
        "\n",
        "                # Write to log file\n",
        "                f.write(log_entry)\n",
        "                f.flush() # Ensure data is written to the file immediately\n",
        "\n",
        "                # Wait for the next interval\n",
        "                time.sleep(5) # Log every 5 seconds\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nMonitoring stopped by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting system performance monitoring. Press Ctrl+C to stop.\")\n",
        "    log_performance_data()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting system performance monitoring. Press Ctrl+C to stop.\n",
            "2025-08-06 08:01:42 - CPU Usage: 98.5%, Memory Usage: 9.4%\n",
            "2025-08-06 08:01:48 - CPU Usage: 43.2%, Memory Usage: 10.9%\n",
            "2025-08-06 08:01:54 - CPU Usage: 3.0%, Memory Usage: 8.2%\n",
            "2025-08-06 08:02:00 - CPU Usage: 3.0%, Memory Usage: 7.6%\n",
            "2025-08-06 08:02:06 - CPU Usage: 54.6%, Memory Usage: 7.7%\n",
            "2025-08-06 08:02:12 - CPU Usage: 1.5%, Memory Usage: 7.6%\n",
            "2025-08-06 08:02:18 - CPU Usage: 3.0%, Memory Usage: 7.8%\n",
            "2025-08-06 08:02:24 - CPU Usage: 9.5%, Memory Usage: 7.4%\n",
            "2025-08-06 08:02:30 - CPU Usage: 2.5%, Memory Usage: 7.4%\n",
            "2025-08-06 08:02:36 - CPU Usage: 3.0%, Memory Usage: 7.4%\n",
            "2025-08-06 08:02:42 - CPU Usage: 3.5%, Memory Usage: 7.5%\n",
            "2025-08-06 08:02:48 - CPU Usage: 3.0%, Memory Usage: 7.5%\n",
            "2025-08-06 08:02:54 - CPU Usage: 2.0%, Memory Usage: 7.4%\n",
            "2025-08-06 08:03:00 - CPU Usage: 2.5%, Memory Usage: 7.4%\n",
            "2025-08-06 08:03:06 - CPU Usage: 2.5%, Memory Usage: 7.5%\n",
            "2025-08-06 08:03:12 - CPU Usage: 3.5%, Memory Usage: 7.5%\n",
            "\n",
            "Monitoring stopped by user.\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "J2MyA5z7wiwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f624548b-0054-496c-bc21-c93411c01238"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# It's best practice to load your key from a secure location,\n",
        "# but for a simple script, you can set it directly.\n",
        "# Replace \"YOUR_API_KEY\" with your actual secret key.\n",
        "client = OpenAI(\n",
        "    api_key=\"sk-...\",\n",
        ")\n",
        "\n",
        "# Step 1: Identify issue\n",
        "prompt1 = \"You are a customer support agent. Ask the customer what issue they are facing.\"\n",
        "\n",
        "response1 = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt1}]\n",
        ")\n",
        "print(response1.choices[0].message.content)\n",
        "\n",
        "# Step 2: Provide a solution (assuming user replied with issue)\n",
        "prompt2 = \"The customer reports a delayed shipment. Provide a professional apology and suggest a next step.\"\n",
        "\n",
        "response2 = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt2}]\n",
        ")\n",
        "print(response2.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "V_FeI2DC4IIs",
        "outputId": "52a50918-95c7-467d-e03f-35d3fa0da0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4064572938.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 1: Identify issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# Step 1: Identify issue\n",
        "prompt1 = \"You are a customer support agent. Ask the customer what issue they are facing.\"\n",
        "\n",
        "response1 = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt1}]\n",
        ")\n",
        "print(response1.choices[0].message.content)\n",
        "\n",
        "# Step 2: Provide a solution (assuming user replied with issue)\n",
        "prompt2 = \"The customer reports a delayed shipment. Provide a professional apology and suggest a next step.\"\n",
        "\n",
        "response2 = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt2}]\n",
        ")\n",
        "print(response2.choices[0].message.content)"
      ],
      "metadata": {
        "id": "crArHPQI3w00"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}